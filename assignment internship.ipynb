{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a468c2-fdcd-4ea0-9933-97f72c50fb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 0: Setup & Configuration Complete ---\n",
      "Pandas version: 2.2.3\n",
      "NumPy version: 2.2.5\n",
      "Seaborn version: 0.13.2\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Phase 1: Data Loading ---\n",
      "Successfully loaded sentiment data from: C:\\Users\\shiva\\Downloads\\fear_greed_index.csv\n",
      "Sentiment Data (Raw) Head:\n",
      "     timestamp  value classification        date\n",
      "0  1517463000     30           Fear  2018-02-01\n",
      "1  1517549400     15   Extreme Fear  2018-02-02\n",
      "2  1517635800     40           Fear  2018-02-03\n",
      "3  1517722200     24   Extreme Fear  2018-02-04\n",
      "4  1517808600     11   Extreme Fear  2018-02-05\n",
      "\n",
      "Successfully loaded trader data from: C:\\Users\\shiva\\Downloads\\historical_data.csv\n",
      "Trader Data (Raw) Head:\n",
      "                                       Account  Coin  Execution Price  \\\n",
      "0  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9769   \n",
      "1  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9800   \n",
      "2  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9855   \n",
      "3  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9874   \n",
      "4  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9894   \n",
      "\n",
      "   Size Tokens  Size USD Side     Timestamp IST  Start Position Direction  \\\n",
      "0       986.87   7872.16  BUY  02-12-2024 22:50        0.000000       Buy   \n",
      "1        16.00    127.68  BUY  02-12-2024 22:50      986.524596       Buy   \n",
      "2       144.09   1150.63  BUY  02-12-2024 22:50     1002.518996       Buy   \n",
      "3       142.98   1142.04  BUY  02-12-2024 22:50     1146.558564       Buy   \n",
      "4         8.73     69.75  BUY  02-12-2024 22:50     1289.488521       Buy   \n",
      "\n",
      "   Closed PnL                                   Transaction Hash     Order ID  \\\n",
      "0         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
      "1         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
      "2         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
      "3         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
      "4         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
      "\n",
      "   Crossed       Fee      Trade ID     Timestamp  \n",
      "0     True  0.345404  8.950000e+14  1.730000e+12  \n",
      "1     True  0.005600  4.430000e+14  1.730000e+12  \n",
      "2     True  0.050431  6.600000e+14  1.730000e+12  \n",
      "3     True  0.050043  1.080000e+15  1.730000e+12  \n",
      "4     True  0.003055  1.050000e+15  1.730000e+12  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Phase 2: Data Preprocessing ---\n",
      "\n",
      "--- 2.1 Preprocessing Sentiment Data ---\n",
      "Sentiment Data (Processed) Head:\n",
      "              timestamp  SentimentValueRaw Classification\n",
      "date                                                    \n",
      "2018-02-01  1517463000                 30           Fear\n",
      "2018-02-02  1517549400                 15   Extreme Fear\n",
      "2018-02-03  1517635800                 40           Fear\n",
      "2018-02-04  1517722200                 24   Extreme Fear\n",
      "2018-02-05  1517808600                 11   Extreme Fear\n",
      "\n",
      "--- 2.2 Preprocessing Trader Data ---\n",
      "INFO: Meaningful 'event' column (e.g., for liquidations) not found in trader data. Event-specific analysis will be limited.\n",
      "INFO: 'Leverage' column not found in trader data. Leverage-specific analysis will be skipped.\n",
      "Total trader records: 211224, BTC records: 26064\n",
      "BTC rows after NaN drop in critical columns: 26064 (removed 0)\n",
      "Trader Data (BTC, Processed) Head:\n",
      "                                          Account symbol  execution_price  \\\n",
      "3001  0x513b8629fe877bb581bf244e326a047b249c4ff1    BTC          82255.0   \n",
      "3002  0x513b8629fe877bb581bf244e326a047b249c4ff1    BTC          82255.0   \n",
      "3003  0x513b8629fe877bb581bf244e326a047b249c4ff1    BTC          82255.0   \n",
      "3004  0x513b8629fe877bb581bf244e326a047b249c4ff1    BTC          82255.0   \n",
      "3005  0x513b8629fe877bb581bf244e326a047b249c4ff1    BTC          82255.0   \n",
      "\n",
      "         size   Size USD side     Timestamp IST  Start Position  Direction  \\\n",
      "3001  0.08585    7061.59  BUY  17-03-2025 04:48         0.00000  Open Long   \n",
      "3002  0.12157    9999.74  BUY  17-03-2025 04:48         0.08585  Open Long   \n",
      "3003  0.00937     770.73  BUY  17-03-2025 04:48         0.20742  Open Long   \n",
      "3004  0.12372   10176.59  BUY  17-03-2025 04:48         0.21679  Open Long   \n",
      "3005  2.64792  217804.66  BUY  17-03-2025 04:48         0.34051  Open Long   \n",
      "\n",
      "      closedPnL                                   Transaction Hash  \\\n",
      "3001        0.0  0x7757437fee55ca858e3f041fb178b10201d700ac1b50...   \n",
      "3002        0.0  0x7757437fee55ca858e3f041fb178b10201d700ac1b50...   \n",
      "3003        0.0  0x7757437fee55ca858e3f041fb178b10201d700ac1b50...   \n",
      "3004        0.0  0x7757437fee55ca858e3f041fb178b10201d700ac1b50...   \n",
      "3005        0.0  0x7757437fee55ca858e3f041fb178b10201d700ac1b50...   \n",
      "\n",
      "         Order ID  Crossed        Fee      Trade ID                time  \\\n",
      "3001  80242832045     True   2.372694  7.470000e+14 1970-01-01 00:29:00   \n",
      "3002  80242832045     True   3.359912  7.020000e+13 1970-01-01 00:29:00   \n",
      "3003  80242832045     True   0.258964  1.970000e+14 1970-01-01 00:29:00   \n",
      "3004  80242832045     True   3.419333  1.090000e+15 1970-01-01 00:29:00   \n",
      "3005  80242832045     True  73.182364  3.470000e+13 1970-01-01 00:29:00   \n",
      "\n",
      "                 event  \n",
      "3001  trade_occurrence  \n",
      "3002  trade_occurrence  \n",
      "3003  trade_occurrence  \n",
      "3004  trade_occurrence  \n",
      "3005  trade_occurrence  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Phase 3: Feature Engineering ---\n",
      "Used 'SentimentValueRaw' for 'SentimentScore'.\n",
      "Sentiment Data with Features (head):\n",
      "              timestamp  SentimentValueRaw Classification  SentimentScore  \\\n",
      "date                                                                       \n",
      "2018-02-01  1517463000                 30           Fear              30   \n",
      "2018-02-02  1517549400                 15   Extreme Fear              15   \n",
      "2018-02-03  1517635800                 40           Fear              40   \n",
      "2018-02-04  1517722200                 24   Extreme Fear              24   \n",
      "2018-02-05  1517808600                 11   Extreme Fear              11   \n",
      "\n",
      "           BroadSentiment  \n",
      "date                       \n",
      "2018-02-01           Fear  \n",
      "2018-02-02           Fear  \n",
      "2018-02-03           Fear  \n",
      "2018-02-04           Fear  \n",
      "2018-02-05           Fear  \n",
      "Trader BTC Data with Features (head):\n",
      "                                          Account symbol  execution_price  \\\n",
      "3001  0x513b8629fe877bb581bf244e326a047b249c4ff1    BTC          82255.0   \n",
      "3002  0x513b8629fe877bb581bf244e326a047b249c4ff1    BTC          82255.0   \n",
      "3003  0x513b8629fe877bb581bf244e326a047b249c4ff1    BTC          82255.0   \n",
      "3004  0x513b8629fe877bb581bf244e326a047b249c4ff1    BTC          82255.0   \n",
      "3005  0x513b8629fe877bb581bf244e326a047b249c4ff1    BTC          82255.0   \n",
      "\n",
      "         size   Size USD side     Timestamp IST  Start Position  Direction  \\\n",
      "3001  0.08585    7061.59  BUY  17-03-2025 04:48         0.00000  Open Long   \n",
      "3002  0.12157    9999.74  BUY  17-03-2025 04:48         0.08585  Open Long   \n",
      "3003  0.00937     770.73  BUY  17-03-2025 04:48         0.20742  Open Long   \n",
      "3004  0.12372   10176.59  BUY  17-03-2025 04:48         0.21679  Open Long   \n",
      "3005  2.64792  217804.66  BUY  17-03-2025 04:48         0.34051  Open Long   \n",
      "\n",
      "      closedPnL                                   Transaction Hash  \\\n",
      "3001        0.0  0x7757437fee55ca858e3f041fb178b10201d700ac1b50...   \n",
      "3002        0.0  0x7757437fee55ca858e3f041fb178b10201d700ac1b50...   \n",
      "3003        0.0  0x7757437fee55ca858e3f041fb178b10201d700ac1b50...   \n",
      "3004        0.0  0x7757437fee55ca858e3f041fb178b10201d700ac1b50...   \n",
      "3005        0.0  0x7757437fee55ca858e3f041fb178b10201d700ac1b50...   \n",
      "\n",
      "         Order ID  Crossed        Fee      Trade ID                time  \\\n",
      "3001  80242832045     True   2.372694  7.470000e+14 1970-01-01 00:29:00   \n",
      "3002  80242832045     True   3.359912  7.020000e+13 1970-01-01 00:29:00   \n",
      "3003  80242832045     True   0.258964  1.970000e+14 1970-01-01 00:29:00   \n",
      "3004  80242832045     True   3.419333  1.090000e+15 1970-01-01 00:29:00   \n",
      "3005  80242832045     True  73.182364  3.470000e+13 1970-01-01 00:29:00   \n",
      "\n",
      "                 event trade_date  is_profit  \n",
      "3001  trade_occurrence 1970-01-01      False  \n",
      "3002  trade_occurrence 1970-01-01      False  \n",
      "3003  trade_occurrence 1970-01-01      False  \n",
      "3004  trade_occurrence 1970-01-01      False  \n",
      "3005  trade_occurrence 1970-01-01      False  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Phase 4: Data Merging ---\n",
      "Rows before merge: 26064, Rows after merge: 26064\n",
      "Rows after dropping non-merged sentiment: 0\n",
      "Merged Data (Head):\n",
      " Empty DataFrame\n",
      "Columns: [Account, symbol, execution_price, size, Size USD, side, Timestamp IST, Start Position, Direction, closedPnL, Transaction Hash, Order ID, Crossed, Fee, Trade ID, time, event, trade_date, is_profit, SentimentScore, BroadSentiment, Classification]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 22 columns]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Phase 5: Exploratory Data Analysis (EDA) ---\n",
      "Merged DataFrame is empty. EDA cannot be performed.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Phase 6: Insight Generation & Strategy Derivation ---\n",
      "No data available for insights as Merged DataFrame is empty.\n",
      "\n",
      "--- Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Phase 0: Setup & Configuration\n",
    "# ---------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"--- Phase 0: Setup & Configuration Complete ---\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Define File Paths (as provided by you)\n",
    "sentiment_file_path = r\"C:\\Users\\shiva\\Downloads\\fear_greed_index.csv\"\n",
    "trader_file_path = r\"C:\\Users\\shiva\\Downloads\\historical_data.csv\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Phase 1: Data Loading\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n--- Phase 1: Data Loading ---\")\n",
    "try:\n",
    "    sentiment_df_raw = pd.read_csv(sentiment_file_path)\n",
    "    print(f\"Successfully loaded sentiment data from: {sentiment_file_path}\")\n",
    "    print(\"Sentiment Data (Raw) Head:\\n\", sentiment_df_raw.head())\n",
    "    # sentiment_df_raw.info() # Uncomment for detailed info\n",
    "except Exception as e:\n",
    "    print(f\"ERROR loading sentiment data: {e}\")\n",
    "    sentiment_df_raw = pd.DataFrame() # Empty df if load fails\n",
    "\n",
    "try:\n",
    "    trader_df_raw = pd.read_csv(trader_file_path)\n",
    "    print(f\"\\nSuccessfully loaded trader data from: {trader_file_path}\")\n",
    "    print(\"Trader Data (Raw) Head:\\n\", trader_df_raw.head())\n",
    "    # trader_df_raw.info() # Uncomment for detailed info\n",
    "except Exception as e:\n",
    "    print(f\"ERROR loading trader data: {e}\")\n",
    "    trader_df_raw = pd.DataFrame() # Empty df if load fails\n",
    "\n",
    "if sentiment_df_raw.empty or trader_df_raw.empty:\n",
    "    print(\"\\nERROR: One or both data files failed to load or are empty. Exiting.\")\n",
    "    raise SystemExit(\"Data loading failed.\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Phase 2: Data Preprocessing\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n--- Phase 2: Data Preprocessing ---\")\n",
    "\n",
    "# --- 2.1 Preprocessing Sentiment Data ---\n",
    "print(\"\\n--- 2.1 Preprocessing Sentiment Data ---\")\n",
    "sentiment_df = sentiment_df_raw.copy()\n",
    "\n",
    "# Column names based on your previous KeyError output for sentiment data\n",
    "# Available columns: ['timestamp', 'value', 'classification', 'date']\n",
    "original_sent_date_col = 'date' # Or 'timestamp' - assuming 'date' is YYYY-MM-DD\n",
    "original_sent_classification_col = 'classification'\n",
    "original_sent_value_col = 'value' # Numeric score (0-100)\n",
    "\n",
    "# Validate and rename sentiment columns\n",
    "if original_sent_date_col not in sentiment_df.columns:\n",
    "    raise KeyError(f\"Sentiment date column '{original_sent_date_col}' not found.\")\n",
    "sentiment_df[original_sent_date_col] = pd.to_datetime(sentiment_df[original_sent_date_col])\n",
    "sentiment_df = sentiment_df.set_index(original_sent_date_col)\n",
    "\n",
    "rename_map_sentiment = {}\n",
    "if original_sent_classification_col in sentiment_df.columns:\n",
    "    rename_map_sentiment[original_sent_classification_col] = 'Classification'\n",
    "if original_sent_value_col in sentiment_df.columns:\n",
    "    rename_map_sentiment[original_sent_value_col] = 'SentimentValueRaw' # Raw numeric score\n",
    "sentiment_df.rename(columns=rename_map_sentiment, inplace=True)\n",
    "\n",
    "print(\"Sentiment Data (Processed) Head:\\n\", sentiment_df.head())\n",
    "# sentiment_df.info()\n",
    "\n",
    "# --- 2.2 Preprocessing Trader Data ---\n",
    "print(\"\\n--- 2.2 Preprocessing Trader Data ---\")\n",
    "trader_df = trader_df_raw.copy()\n",
    "\n",
    "# Column names based on your previous KeyError output for trader data\n",
    "# Available: ['Account', 'Coin', 'Execution Price', 'Size Tokens', 'Size USD', 'Side',\n",
    "# 'Timestamp IST', 'Start Position', 'Direction', 'Closed PnL', 'Transaction Hash',\n",
    "# 'Order ID', 'Crossed', 'Fee', 'Trade ID', 'Timestamp']\n",
    "original_trader_time_col = 'Timestamp' # Or 'Timestamp IST'\n",
    "original_trader_symbol_col = 'Coin'\n",
    "original_trader_pnl_col = 'Closed PnL'\n",
    "original_trader_exec_price_col = 'Execution Price'\n",
    "original_trader_size_col = 'Size Tokens' # Using token size for asset quantity\n",
    "original_trader_side_col = 'Side'\n",
    "\n",
    "# Columns NOT found in your trader data's available list, so set to None:\n",
    "original_trader_event_col = None # No direct 'event' type column like 'fill', 'liquidation'\n",
    "original_trader_leverage_col = None # No 'leverage' column\n",
    "\n",
    "trader_rename_map = {}\n",
    "if original_trader_time_col in trader_df.columns: trader_rename_map[original_trader_time_col] = 'time'\n",
    "if original_trader_symbol_col in trader_df.columns: trader_rename_map[original_trader_symbol_col] = 'symbol'\n",
    "if original_trader_pnl_col in trader_df.columns: trader_rename_map[original_trader_pnl_col] = 'closedPnL'\n",
    "if original_trader_exec_price_col in trader_df.columns: trader_rename_map[original_trader_exec_price_col] = 'execution_price'\n",
    "if original_trader_size_col in trader_df.columns: trader_rename_map[original_trader_size_col] = 'size'\n",
    "if original_trader_side_col in trader_df.columns: trader_rename_map[original_trader_side_col] = 'side'\n",
    "\n",
    "# Handle missing 'event' and 'leverage'\n",
    "has_event_column = False\n",
    "if original_trader_event_col and original_trader_event_col in trader_df.columns:\n",
    "    trader_rename_map[original_trader_event_col] = 'event'\n",
    "    has_event_column = True\n",
    "else:\n",
    "    print(\"INFO: Meaningful 'event' column (e.g., for liquidations) not found in trader data. Event-specific analysis will be limited.\")\n",
    "    trader_df['event'] = 'trade_occurrence' # Placeholder if needed by structure\n",
    "\n",
    "has_leverage_column = False\n",
    "if original_trader_leverage_col and original_trader_leverage_col in trader_df.columns:\n",
    "    trader_rename_map[original_trader_leverage_col] = 'leverage'\n",
    "    has_leverage_column = True\n",
    "else:\n",
    "    print(\"INFO: 'Leverage' column not found in trader data. Leverage-specific analysis will be skipped.\")\n",
    "\n",
    "trader_df.rename(columns=trader_rename_map, inplace=True)\n",
    "\n",
    "# Validate essential columns after renaming\n",
    "essential_cols = ['time', 'symbol', 'closedPnL', 'execution_price', 'size', 'side']\n",
    "for col in essential_cols:\n",
    "    if col not in trader_df.columns:\n",
    "        raise KeyError(f\"Trader data missing essential column '{col}' after renaming.\")\n",
    "\n",
    "# Convert 'time' column\n",
    "try:\n",
    "    trader_df['time'] = pd.to_datetime(trader_df['time'])\n",
    "except Exception: # Broad exception for various parsing issues\n",
    "    try:\n",
    "        print(\"Attempting to parse trader 'time' column as Unix timestamp (ms)...\")\n",
    "        trader_df['time'] = pd.to_datetime(trader_df['time'], unit='ms')\n",
    "    except Exception as e_time:\n",
    "        print(f\"ERROR: Failed to parse trader 'time' column: {e_time}\")\n",
    "        raise\n",
    "\n",
    "# Filter for BTC trades\n",
    "btc_symbol_pattern = 'BTC' # Adjust if your BTC symbol is more specific (e.g., 'BTC-PERP')\n",
    "trader_df_btc = trader_df[trader_df['symbol'].astype(str).str.contains(btc_symbol_pattern, case=False, na=False)].copy()\n",
    "print(f\"Total trader records: {len(trader_df)}, BTC records: {len(trader_df_btc)}\")\n",
    "if trader_df_btc.empty:\n",
    "    print(\"WARNING: No BTC trades found after filtering. Analysis will be on an empty dataset.\")\n",
    "\n",
    "# Convert PnL, size, price to numeric; coercing errors\n",
    "trader_df_btc['closedPnL'] = pd.to_numeric(trader_df_btc['closedPnL'], errors='coerce')\n",
    "trader_df_btc['size'] = pd.to_numeric(trader_df_btc['size'], errors='coerce')\n",
    "trader_df_btc['execution_price'] = pd.to_numeric(trader_df_btc['execution_price'], errors='coerce')\n",
    "if has_leverage_column and 'leverage' in trader_df_btc.columns: # Only if leverage column exists\n",
    "    trader_df_btc['leverage'] = pd.to_numeric(trader_df_btc['leverage'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN in critical numeric columns or 'side'\n",
    "cols_to_check_na = ['closedPnL', 'size', 'execution_price', 'side']\n",
    "if has_leverage_column and 'leverage' in trader_df_btc.columns:\n",
    "    cols_to_check_na.append('leverage')\n",
    "\n",
    "initial_btc_rows = len(trader_df_btc)\n",
    "trader_df_btc.dropna(subset=[col for col in cols_to_check_na if col in trader_df_btc.columns], inplace=True)\n",
    "print(f\"BTC rows after NaN drop in critical columns: {len(trader_df_btc)} (removed {initial_btc_rows - len(trader_df_btc)})\")\n",
    "\n",
    "print(\"Trader Data (BTC, Processed) Head:\\n\", trader_df_btc.head())\n",
    "# trader_df_btc.info()\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Phase 3: Feature Engineering\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n--- Phase 3: Feature Engineering ---\")\n",
    "\n",
    "# --- 3.1 Sentiment Feature Engineering ---\n",
    "if 'SentimentValueRaw' in sentiment_df.columns:\n",
    "    sentiment_df['SentimentScore'] = sentiment_df['SentimentValueRaw'] # Using the direct numeric score\n",
    "    print(\"Used 'SentimentValueRaw' for 'SentimentScore'.\")\n",
    "else:\n",
    "    # Fallback to mapping text if numeric score isn't available/reliable\n",
    "    print(\"Warning: 'SentimentValueRaw' not found. Attempting to map 'Classification' text for 'SentimentScore'.\")\n",
    "    sentiment_mapping = {'Extreme Fear': 1, 'Fear': 2, 'Neutral': 3, 'Greed': 4, 'Extreme Greed': 5}\n",
    "    if 'Classification' in sentiment_df.columns:\n",
    "        sentiment_df['SentimentScore'] = sentiment_df['Classification'].map(sentiment_mapping)\n",
    "    else:\n",
    "        print(\"ERROR: Neither 'SentimentValueRaw' nor 'Classification' found for SentimentScore creation.\")\n",
    "        sentiment_df['SentimentScore'] = np.nan # Placeholder\n",
    "\n",
    "if 'Classification' in sentiment_df.columns:\n",
    "    def get_broad_sentiment(text_classification):\n",
    "        if pd.isna(text_classification): return 'Neutral'\n",
    "        text_classification = str(text_classification).lower()\n",
    "        if 'extreme fear' in text_classification or 'fear' in text_classification: return 'Fear'\n",
    "        if 'extreme greed' in text_classification or 'greed' in text_classification: return 'Greed'\n",
    "        return 'Neutral'\n",
    "    sentiment_df['BroadSentiment'] = sentiment_df['Classification'].apply(get_broad_sentiment)\n",
    "else:\n",
    "    print(\"Warning: 'Classification' column not available for 'BroadSentiment'. Setting to 'Neutral'.\")\n",
    "    sentiment_df['BroadSentiment'] = 'Neutral'\n",
    "\n",
    "print(\"Sentiment Data with Features (head):\\n\", sentiment_df.head())\n",
    "\n",
    "# --- 3.2 Trader Feature Engineering ---\n",
    "if not trader_df_btc.empty:\n",
    "    trader_df_btc['trade_date'] = trader_df_btc['time'].dt.normalize() # Date part for merging\n",
    "    trader_df_btc['is_profit'] = trader_df_btc['closedPnL'] > 0\n",
    "    print(\"Trader BTC Data with Features (head):\\n\", trader_df_btc.head())\n",
    "else:\n",
    "    print(\"Trader BTC data is empty, skipping feature engineering for it.\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Phase 4: Data Merging\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n--- Phase 4: Data Merging ---\")\n",
    "if not trader_df_btc.empty and 'trade_date' in trader_df_btc.columns:\n",
    "    merged_df = pd.merge(trader_df_btc, sentiment_df[['SentimentScore', 'BroadSentiment', 'Classification']], # Select specific columns\n",
    "                         left_on='trade_date', right_index=True, how='left')\n",
    "    print(f\"Rows before merge: {len(trader_df_btc)}, Rows after merge: {len(merged_df)}\")\n",
    "\n",
    "    # Drop rows where sentiment data couldn't be merged\n",
    "    merged_df.dropna(subset=['SentimentScore', 'BroadSentiment'], inplace=True)\n",
    "    print(f\"Rows after dropping non-merged sentiment: {len(merged_df)}\")\n",
    "    print(\"Merged Data (Head):\\n\", merged_df.head())\n",
    "else:\n",
    "    print(\"Trader BTC data is empty or 'trade_date' missing. Cannot merge. EDA will be skipped.\")\n",
    "    merged_df = pd.DataFrame() # Ensure merged_df exists as empty if merge fails\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Phase 5: Exploratory Data Analysis (EDA)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n--- Phase 5: Exploratory Data Analysis (EDA) ---\")\n",
    "if merged_df.empty:\n",
    "    print(\"Merged DataFrame is empty. EDA cannot be performed.\")\n",
    "else:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid') # Set a pleasant style\n",
    "\n",
    "    # 5.1 Overall PnL Distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(merged_df['closedPnL'], kde=True, bins=50)\n",
    "    plt.title('Distribution of Closed PnL (BTC Trades)')\n",
    "    plt.xlabel('Closed PnL'); plt.ylabel('Frequency'); plt.show()\n",
    "    print(\"PnL Stats:\\n\", merged_df['closedPnL'].describe())\n",
    "\n",
    "    # 5.2 Sentiment Distribution on Traded Days\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    merged_df['BroadSentiment'].value_counts(normalize=True).sort_index().plot(kind='bar', color=['red', 'lightgray', 'green'])\n",
    "    plt.title('Sentiment Distribution on Traded Days')\n",
    "    plt.ylabel('Proportion of Trades'); plt.xticks(rotation=0); plt.show()\n",
    "\n",
    "    # 5.3 PnL by Sentiment\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=merged_df, x='BroadSentiment', y='closedPnL', order=['Fear', 'Neutral', 'Greed'])\n",
    "    plt.title('PnL Distribution by Broad Sentiment')\n",
    "    # Consider y-axis limits if outliers are extreme: merged_df['closedPnL'].quantile([0.05, 0.95])\n",
    "    plt.show()\n",
    "    print(\"Average PnL by Sentiment:\\n\", merged_df.groupby('BroadSentiment')['closedPnL'].mean().reindex(['Fear', 'Neutral', 'Greed']))\n",
    "\n",
    "    # 5.4 Win Rate by Sentiment\n",
    "    win_rate_df = merged_df.groupby('BroadSentiment')['is_profit'].mean().reindex(['Fear', 'Neutral', 'Greed'])\n",
    "    print(\"Win Rate by Sentiment:\\n\", win_rate_df)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    win_rate_df.plot(kind='bar', color=['red', 'lightgray', 'green'])\n",
    "    plt.title('Win Rate by Broad Sentiment'); plt.ylabel('Win Rate'); plt.ylim(0,1); plt.xticks(rotation=0); plt.show()\n",
    "\n",
    "    # 5.5 Leverage Analysis (Conditional)\n",
    "    if has_leverage_column and 'leverage' in merged_df.columns:\n",
    "        print(\"\\n--- Leverage Analysis ---\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(data=merged_df, x='BroadSentiment', y='leverage', order=['Fear', 'Neutral', 'Greed'])\n",
    "        plt.title('Leverage Distribution by Sentiment'); plt.show()\n",
    "        print(\"Average Leverage by Sentiment:\\n\", merged_df.groupby('BroadSentiment')['leverage'].mean().reindex(['Fear', 'Neutral', 'Greed']))\n",
    "\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        sns.scatterplot(data=merged_df, x='leverage', y='closedPnL', hue='BroadSentiment', alpha=0.5,\n",
    "                        palette={'Fear':'red', 'Neutral':'lightgray', 'Greed':'green'})\n",
    "        plt.title('PnL vs. Leverage, Colored by Sentiment'); plt.axhline(0, color='k', linestyle='--', lw=0.8); plt.show()\n",
    "    else:\n",
    "        print(\"\\nINFO: Leverage column not available. Skipping leverage-specific EDA.\")\n",
    "\n",
    "    # 5.6 Trading Activity (Size, Count) by Sentiment\n",
    "    print(\"\\n--- Trading Activity Analysis ---\")\n",
    "    activity_df = merged_df.groupby('BroadSentiment').agg(\n",
    "        num_trades=('symbol', 'count'),\n",
    "        avg_trade_size=('size', 'mean'),\n",
    "        total_trade_size=('size', 'sum')\n",
    "    ).reindex(['Fear', 'Neutral', 'Greed'])\n",
    "    print(\"Trading Activity by Sentiment:\\n\", activity_df)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    activity_df['num_trades'].plot(kind='bar', ax=axes[0], title='Number of Trades by Sentiment', color=['red', 'lightgray', 'green'])\n",
    "    activity_df['avg_trade_size'].plot(kind='bar', ax=axes[1], title='Average Trade Size by Sentiment', color=['red', 'lightgray', 'green'])\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # 5.7 Trade Side (Buy/Sell) Performance by Sentiment\n",
    "    print(\"\\n--- Trade Side Performance Analysis ---\")\n",
    "    side_perf_df = merged_df.groupby(['BroadSentiment', 'side'])['closedPnL'].agg(['mean', 'count']).unstack()\n",
    "    print(\"PnL by Sentiment and Trade Side:\\n\", side_perf_df)\n",
    "    if not side_perf_df.empty and ('mean', 'buy') in side_perf_df.columns and ('mean', 'sell') in side_perf_df.columns:\n",
    "         side_perf_df[('mean')].reindex(['Fear', 'Neutral', 'Greed']).plot(kind='bar', figsize=(10,6))\n",
    "         plt.title('Average PnL by Sentiment and Trade Side'); plt.ylabel('Average PnL'); plt.xticks(rotation=0); plt.show()\n",
    "    else:\n",
    "        print(\"Not enough data diversity for side performance plot.\")\n",
    "    \n",
    "    # 5.8 Event Analysis (Limited due to missing specific event column)\n",
    "    if 'event' in merged_df.columns and merged_df['event'].nunique() > 1 and merged_df['event'].iloc[0] != 'trade_occurrence': # Check if not just placeholder\n",
    "        print(\"\\n--- Event Analysis (if meaningful events exist) ---\")\n",
    "        print(\"Event Counts:\\n\", merged_df['event'].value_counts())\n",
    "        # If you identify a specific event string like 'liquidation' in your actual data (not the placeholder):\n",
    "        # liquidation_str = 'YOUR_LIQUIDATION_EVENT_STRING'\n",
    "        # liquidations = merged_df[merged_df['event'] == liquidation_str]\n",
    "        # if not liquidations.empty:\n",
    "        #     liquidations.groupby('BroadSentiment').size().reindex(['Fear', 'Neutral', 'Greed']).plot(kind='bar', title='Liquidations by Sentiment')\n",
    "        #     plt.show()\n",
    "    else:\n",
    "        print(\"\\nINFO: No distinct event types found or using placeholder 'event'. Detailed event analysis skipped.\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Phase 6: Insight Generation & Strategy Derivation\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n--- Phase 6: Insight Generation & Strategy Derivation ---\")\n",
    "if merged_df.empty:\n",
    "    print(\"No data available for insights as Merged DataFrame is empty.\")\n",
    "else:\n",
    "    print(\"\\nKey Observations (based on this specific dataset analysis):\")\n",
    "    # General PnL\n",
    "    overall_avg_pnl = merged_df['closedPnL'].mean()\n",
    "    print(f\"- Overall average PnL per trade: {overall_avg_pnl:.2f}.\")\n",
    "\n",
    "    # PnL by Sentiment\n",
    "    avg_pnl_fear = merged_df[merged_df['BroadSentiment'] == 'Fear']['closedPnL'].mean()\n",
    "    avg_pnl_neutral = merged_df[merged_df['BroadSentiment'] == 'Neutral']['closedPnL'].mean()\n",
    "    avg_pnl_greed = merged_df[merged_df['BroadSentiment'] == 'Greed']['closedPnL'].mean()\n",
    "    print(f\"- Average PnL during Fear: {avg_pnl_fear:.2f}, Neutral: {avg_pnl_neutral:.2f}, Greed: {avg_pnl_greed:.2f}.\")\n",
    "    if avg_pnl_fear > avg_pnl_greed and avg_pnl_fear > avg_pnl_neutral:\n",
    "        print(\"  > Trades during 'Fear' periods showed the highest average PnL.\")\n",
    "    elif avg_pnl_greed > avg_pnl_fear and avg_pnl_greed > avg_pnl_neutral:\n",
    "        print(\"  > Trades during 'Greed' periods showed the highest average PnL.\")\n",
    "\n",
    "    # Win Rate by Sentiment\n",
    "    win_rate_fear = merged_df[merged_df['BroadSentiment'] == 'Fear']['is_profit'].mean()\n",
    "    win_rate_greed = merged_df[merged_df['BroadSentiment'] == 'Greed']['is_profit'].mean()\n",
    "    print(f\"- Win rate during Fear: {win_rate_fear:.2%}, Greed: {win_rate_greed:.2%}.\")\n",
    "    if win_rate_fear > win_rate_greed:\n",
    "        print(\"  > Win rates appear higher during 'Fear' periods.\")\n",
    "    elif win_rate_greed > win_rate_fear:\n",
    "         print(\"  > Win rates appear higher during 'Greed' periods.\")\n",
    "\n",
    "    # Leverage Insights (if available)\n",
    "    if has_leverage_column and 'leverage' in merged_df.columns:\n",
    "        avg_leverage_fear = merged_df[merged_df['BroadSentiment'] == 'Fear']['leverage'].mean()\n",
    "        avg_leverage_greed = merged_df[merged_df['BroadSentiment'] == 'Greed']['leverage'].mean()\n",
    "        print(f\"- Average leverage during Fear: {avg_leverage_fear:.2f}x, Greed: {avg_leverage_greed:.2f}x.\")\n",
    "        # Further insights would come from visually inspecting PnL vs Leverage plot.\n",
    "        print(\"  > (Visual inspection needed for PnL vs Leverage correlation by sentiment).\")\n",
    "    else:\n",
    "        print(\"- Leverage data was not available for detailed insights.\")\n",
    "\n",
    "    print(\"\\nPotential Strategy Considerations (Illustrative - Requires Rigorous Backtesting):\")\n",
    "    print(\"1. Sentiment-Biased Direction: If analysis consistently shows, for example, that long positions perform better in 'Greed' and shorts in 'Fear', traders could consider aligning their primary trade direction with strong sentiment signals.\")\n",
    "    print(\"2. Contrarian Opportunities: If periods of 'Extreme Fear' (low SentimentScore) are often followed by reversals, this could signal contrarian buying opportunities, especially if win rates improve then.\")\n",
    "    print(\"3. Risk Adjustment by Sentiment: If volatility or losses are notably higher during 'Fear' (even without leverage data), traders might consider reducing position sizes or tightening stop-losses during such periods.\")\n",
    "    print(\"4. Activity Monitoring: If trade volume or frequency significantly changes with sentiment, this could indicate broader market participation shifts that might precede price movements.\")\n",
    "\n",
    "    print(\"\\nLimitations & Next Steps:\")\n",
    "    print(\"- The analysis is based on historical data and does not guarantee future performance.\")\n",
    "    if not has_leverage_column:\n",
    "        print(\"- Lack of 'leverage' data limits understanding of risk-taking behavior.\")\n",
    "    if not has_event_column or (has_event_column and merged_df['event'].iloc[0] == 'trade_occurrence'):\n",
    "        print(\"- Lack of specific 'event' data (e.g., liquidations) limits analysis of extreme market events.\")\n",
    "    print(\"- Further analysis could involve: lagged sentiment effects, trader segmentation (if 'Account' data were used), and statistical significance testing of observed differences.\")\n",
    "\n",
    "print(\"\\n--- Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcb8624-4e82-4645-be3e-2494cf8c9a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cedb7e9-0e10-47e2-8535-0c3c790df8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
